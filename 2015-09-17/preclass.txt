If you are lost with the numerical aspects of the pre-class questions,
please ask about them on Piazza or in office hours!  The intent is
that we will focus on the computational patterns of the methods rather
than on the numerical analysis, but I am working under the assumption
that you can figure out the numerical jargon.

0.  How much time did you spend on this pre-class exercise, and when?

    1 hour and 10 minutes
    11:00 am on Wednesday

1.  What are one or two points that you found least clear in the
    9/17 slide decks (including the narration)?

    explicit time steps and batching time steps

2.  Fill in the most straightforward implementation you can think of
    for multiplying a compressed sparse row matrix by a vector.
    Note: It is fine to look up the answer elsewhere!  If you do,
    please just say where you looked.

      typedef struct csr_t {
          int  n;   /* Dimension of matrix (assume square) */
          int* pr;  /* Array of matrix nonzeros (row major order) */
          int* col; /* Column indices of nonzeros *
          int* ptr; /* Offsets of the start of each row in pr
                       (ptr[n] = number of nonzeros) */
      } csr_t;
    
      void sparse_multiply(csr_t* A, double* x, double* result)
      {
          for (int i = 0; i < n; ++i) {
              result[i] = 0.0;
              for (int j = A->ptr[i]; j < A->ptr[i + 1]; ++j) {
                  result[i] += A->pr[j] * x[A->col[j]];
              }
          }     
      } 

3.  From the slides, complete the following short code:

      double laplacian_u(double (*u)(double x, double y),
                         double h, double x, double y)
      {
          ux2 = (u(x - h, y) - 2 * u(x, y) + u(x + h, y)) / h / h;
          uy2 = (u(x, y - h) - 2 * u(x, y) + u(x, y + h)) / h / h;
          return ux2 + uy2;
      }

    If you are unfamiliar with the syntax, the first argument to
    laplacian_u is a C function pointer -- within the function,
    it can be called in the same way as an ordinary function (i.e.
    u(x,y)).  See the laplace2d.c code in this directory as an example.

4.  In one space dimension, the following numerical scheme
    approximately solves the wave equation

        u_tt = c^2 u_xx

    with zero boundary conditions at the end of the interval and
    given initial values u(0,x) = f(x) and time derivatives
    u'(0,x) = g(x).

      u[0,k] = f(x[k])
      u[1,k] = s^2/2 * (f[k+1]+f[k-1]) + (1-s^2)*f[k] + dt * g[k]

      for j = 1 to nsteps
          u[j+1,k] = s^2 * (u[j,k+1]+u[j,k-1]) + 2*(1-s^2)*u[j,k] - u[j-1,k]

    where u[j,k] corresponds to the solution at time step j (time j*dt)
    and grid node k, and s = c*dt/dx.  Following the pattern shown in
    the slides for advancing a parallel explicit heat equation solver by
    several steps without communicating, can you describe how to
    similarly advance this scheme?  Are there any advantages to such
    an organization if there is only one core available?

    u[j + 1, k] depends on u[j, k + 1], u[j, k - 1], u[j, k], u[j - 1, k]
    
    similarly,
    u[j + s, k] depends on u[j, k + s], ..., u[j, k - s] 
                       and u[j - 1, k + s - 1], ..., u[j - 1, k - s + 1]

    in order to go s steps without communication,
    we can store (2 * s - 1) ghost nodes corresponding to u[#, -s], ..., u[#, -1]
             and (2 * s - 1) ghost nodes corresponding to u[#, K + 1], ..., u[#, K + s]

    if we divide the grid u[#, #] into smaller blocks and make a block with its ghost nodes fit in the cache, there is still advantages to such an organization even if there is only one core available




