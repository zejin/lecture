0.  How much time did you spend on this pre-class exercise, and when?

    1 hour
    12:00 am on Wednesday    

1.  What are one or two points that you found least clear in the
    10/08 slide decks (including the narration)?

    on page 11 of mpi:
    how buffers function in nonblocking communication?

2.  Now that we are now basically a third of the way into the
    semester, and are (mostly) settled into the steady pace of things,
    I would appreciate your feedback on what is working well or poorly
    about the class.  Comments on things I can reasonably change are
    particularly useful -- venting about the cluster, for example, is
    understandable but doesn't help me that much in adjusting!

    I hope there are more summaries and comparisons.
    For example, what is the difference between OpenMP, MPI and Offload?

3.  The ring demo implements the protocol described in the particle
    systems slide deck from 9/15:

    http://cornell-cs5220-f15.github.io/slides/2015-09-15-particle.html#/11

    a) In your own words, describe what ring.c is doing.

       calculate the sum of absolute difference between each element and all elements in its process and previous process  

    b) How might you modify the code to have the same computational
       pattern, but using non-blocking communication rather than
       MPI_Sendrecv?  Note that according to the MPI standard,
       one isn't supposed to read from a buffer that is being
       handled by a non-blocking send, so it is probably necessary
       to use three temporary buffers rather than the current two.

       use another sent buffer to avoid the swap between current and received buffer   

       double* curr_buf = (double*) malloc(nper * sizeof(double));
       double* send_buf = (double*) malloc(nper * sizeof(double));
       double* recv_buf = (double*) malloc(nper * sizeof(double));

       memcpy(send_buf, my_data, nper * sizeof(double));
        
       MPI_Isend(send_buf, nper, MPI_DOUBLE, next, phase, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
       MPI_Irecv(recv_buf, nper, MPI_DOUBLE, prev, phase, MPI_COMM_WORLD, MPI_STATUS_IGNORE);

       MPI_Wait(request, status);

       memcpy(curr_buf, recv_buf, nper * sizeof(double));
